---
l1idx: 1
l2idx: 2
l3idx: 7
l4idx: 5
title: "Kubernetes Networking Considerations"
permalink: 1_2_7_5.html
summary: "Kubernetes introduces an overlay network all of its own (most of the time)"
---

On a Kubernetes worker node, a Linux host runs a nominal container runtime, which virtualizes the host operating system for presentation to processes running within individual "containers" (grouped as pods.)  The Kubernetes "container network interface"  (CNI) defines a standard set of abstractions for how network services are extended to the containers. 

The Kubernetes worker node configures a dedicated Linux network namespace (NS) for each pod.  It also configures a pair logical/virtual "veth" interface-pair.  The veth construct is a pair of virtual ethernet interfaces that forward traffic directly to each other.  If a packet goes into one interface on the veth pair; it immediately emerges from the other interface in the veth pair.  The pod-dedicated veth pair puts one interface in the pod's NS, and the other interface in the host's default NS.  This is the mechanism (NS straddling by veths) by which the pod can send traffic to/through the host.  Each pod's NS consumes the virtualized network services exposed by the host OS, including Linux's TCP implementation, which includes the following functionality:

- Enabling/disabling path MTU discovery
- Enabling/disable packetization-layer path MTU discovery

Interface MTU is  configured on a per interface basis on Linux hosts, so it is incumbent on the Kubernetes platform to configure an appropriate interface MTU on the container/pod-facing veth interface.

When the K8s worker node's main/default NS receives a packet from a pod/container (via the default-NS-facing interface on a veth pair), it is responsible for handling that packet.  The Kubernetes CNI is responsible for configuring the host to do exactly that.  Some CNIs will just rely on the native Linux networking stack to forward those packets; others will have implemented SDN control of the Linux virtual switch (vswitch) and explicitly programmed flow-rules to define the forwarding rules for each permitted flow.  Regardless of the model in use, the hop that the traffic takes on its way through the host's default NS is an opportunity for MTU mismatch to occur. 

- If both interfaces in the veth pair don't have the same MTU
- If the veth interfaces' MTUs are larger than the physical NIC's MTU
- If the main/default NS is performing any type of overlay encapsulation before forwarding the traffic through the physical NIC
